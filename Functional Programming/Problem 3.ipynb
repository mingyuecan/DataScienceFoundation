{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nose.tools import assert_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New #job opening at The Ottawa Hospital in #Ottawa - #Clinical #Informatics Specialist #jobs http://t.co/3SlUy11dro', 'Looking for a #Clinical #Informatics Pharmacist Park Plaza Hospital #jobs http://t.co/4Qw8i6YaJI', 'Info Session 10/7: MSc in Biomedical Informatics, University of Chicago https://t.co/65G8dJmhdR #HIT #UChicago #informatics #healthcare', \"Here's THE best #Books I've read on #EHR #HIE #HIPAA and #Health #Informatics http://t.co/meFE0dMSPe\", '@RMayNurseDir @FNightingaleF Scholars talking passionately about what they believe in. #informatics &amp; #skincare  https://t.co/m8qiUSxk0h']\n"
     ]
    }
   ],
   "source": [
    "tweets = '''\n",
    "New #job opening at The Ottawa Hospital in #Ottawa - #Clinical #Informatics Specialist #jobs http://t.co/3SlUy11dro\n",
    "Looking for a #Clinical #Informatics Pharmacist Park Plaza Hospital #jobs http://t.co/4Qw8i6YaJI\n",
    "Info Session 10/7: MSc in Biomedical Informatics, University of Chicago https://t.co/65G8dJmhdR #HIT #UChicago #informatics #healthcare\n",
    "Here's THE best #Books I've read on #EHR #HIE #HIPAA and #Health #Informatics http://t.co/meFE0dMSPe\n",
    "@RMayNurseDir @FNightingaleF Scholars talking passionately about what they believe in. #informatics &amp; #skincare  https://t.co/m8qiUSxk0h\n",
    "'''.strip().split('\\n')\n",
    "\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use list comprehensions to split the text into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_into_words(tweets):\n",
    "    '''\n",
    "    Takes a list of tweets, and returns a nested list of words in all tweets.\n",
    "    Since words are separated by one or more whitespaces,\n",
    "    the return value is a list of lists of strings with no whitespace.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tweets: a list of strings. Strings have whitespaces.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A nested list of strings. Strings have no whitespace.\n",
    "    Results from splitting each tweet in tweets by whitespace.\n",
    "    '''\n",
    "    \n",
    "    result=[j for j in [i.split() for i in tweets]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['New', '#job', 'opening', 'at', 'The', 'Ottawa', 'Hospital', 'in', '#Ottawa', '-', '#Clinical', '#Informatics', 'Specialist', '#jobs', 'http://t.co/3SlUy11dro'], ['Looking', 'for', 'a', '#Clinical', '#Informatics', 'Pharmacist', 'Park', 'Plaza', 'Hospital', '#jobs', 'http://t.co/4Qw8i6YaJI'], ['Info', 'Session', '10/7:', 'MSc', 'in', 'Biomedical', 'Informatics,', 'University', 'of', 'Chicago', 'https://t.co/65G8dJmhdR', '#HIT', '#UChicago', '#informatics', '#healthcare'], [\"Here's\", 'THE', 'best', '#Books', \"I've\", 'read', 'on', '#EHR', '#HIE', '#HIPAA', 'and', '#Health', '#Informatics', 'http://t.co/meFE0dMSPe'], ['@RMayNurseDir', '@FNightingaleF', 'Scholars', 'talking', 'passionately', 'about', 'what', 'they', 'believe', 'in.', '#informatics', '&amp;', '#skincare', 'https://t.co/m8qiUSxk0h']]\n"
     ]
    }
   ],
   "source": [
    "words = split_into_words(tweets)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assertion test\n",
    "words_answer = [\n",
    "    ['New', '#job', 'opening', 'at', 'The', 'Ottawa', 'Hospital', 'in', '#Ottawa', '-',\n",
    "    '#Clinical', '#Informatics', 'Specialist', '#jobs', 'http://t.co/3SlUy11dro'],\n",
    "    \n",
    "    ['Looking', 'for', 'a', '#Clinical', '#Informatics', 'Pharmacist', 'Park', 'Plaza', 'Hospital',\n",
    "    '#jobs', 'http://t.co/4Qw8i6YaJI'],\n",
    "    \n",
    "    ['Info', 'Session', '10/7:', 'MSc', 'in', 'Biomedical', 'Informatics,', 'University', 'of', 'Chicago',\n",
    "    'https://t.co/65G8dJmhdR', '#HIT', '#UChicago', '#informatics', '#healthcare'],\n",
    "    \n",
    "    [\"Here's\", 'THE', 'best', '#Books', \"I've\", 'read', 'on', '#EHR', '#HIE', '#HIPAA',\n",
    "    'and', '#Health', '#Informatics', 'http://t.co/meFE0dMSPe'],\n",
    "    \n",
    "    ['@RMayNurseDir', '@FNightingaleF', 'Scholars', 'talking', 'passionately', 'about', 'what', 'they', 'believe', 'in.',\n",
    "    '#informatics', '&amp;', '#skincare', 'https://t.co/m8qiUSxk0h']\n",
    "]\n",
    "\n",
    "assert_equal(words, words_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use the map function to split the text into words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_into_words(tweets):\n",
    "    '''\n",
    "    Takes a list of tweets, and returns a nested list of words in all tweets.\n",
    "    Since words are separated by one or more whitespaces,\n",
    "    the return value is a list of lists of strings with no whitespace.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tweets: a list of strings. Strings have whitespaces.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A nested list of strings. Strings have no whitespace.\n",
    "    Results from splitting each tweet in tweets by whitespace.\n",
    "    '''\n",
    "    \n",
    "    return list(map(str.split, tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['New', '#job', 'opening', 'at', 'The', 'Ottawa', 'Hospital', 'in', '#Ottawa', '-', '#Clinical', '#Informatics', 'Specialist', '#jobs', 'http://t.co/3SlUy11dro'], ['Looking', 'for', 'a', '#Clinical', '#Informatics', 'Pharmacist', 'Park', 'Plaza', 'Hospital', '#jobs', 'http://t.co/4Qw8i6YaJI'], ['Info', 'Session', '10/7:', 'MSc', 'in', 'Biomedical', 'Informatics,', 'University', 'of', 'Chicago', 'https://t.co/65G8dJmhdR', '#HIT', '#UChicago', '#informatics', '#healthcare'], [\"Here's\", 'THE', 'best', '#Books', \"I've\", 'read', 'on', '#EHR', '#HIE', '#HIPAA', 'and', '#Health', '#Informatics', 'http://t.co/meFE0dMSPe'], ['@RMayNurseDir', '@FNightingaleF', 'Scholars', 'talking', 'passionately', 'about', 'what', 'they', 'believe', 'in.', '#informatics', '&amp;', '#skincare', 'https://t.co/m8qiUSxk0h']]\n"
     ]
    }
   ],
   "source": [
    "mapped_words = map_into_words(tweets)\n",
    "print(mapped_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert_equal(mapped_words, words_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten the nested list (code provided)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(tweets):\n",
    "    '''\n",
    "    Flattens a nested list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tweets: a list of lists.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A flat list.\n",
    "    '''\n",
    "    \n",
    "    return [t for tweet in tweets for t in tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flattened_words = flatten(words)\n",
    "\n",
    "flattened_words_answer = [\n",
    "    'New', '#job', 'opening', 'at', 'The', 'Ottawa', 'Hospital', 'in', '#Ottawa', '-',\n",
    "    '#Clinical', '#Informatics', 'Specialist', '#jobs', 'http://t.co/3SlUy11dro',\n",
    "    \n",
    "    'Looking', 'for', 'a', '#Clinical', '#Informatics', 'Pharmacist', 'Park', 'Plaza', 'Hospital',\n",
    "    '#jobs', 'http://t.co/4Qw8i6YaJI',\n",
    "    \n",
    "    'Info', 'Session', '10/7:', 'MSc', 'in', 'Biomedical', 'Informatics,', 'University', 'of', 'Chicago',\n",
    "    'https://t.co/65G8dJmhdR', '#HIT', '#UChicago', '#informatics', '#healthcare',\n",
    "    \n",
    "    \"Here's\", 'THE', 'best', '#Books', \"I've\", 'read', 'on', '#EHR', '#HIE', '#HIPAA',\n",
    "    'and', '#Health', '#Informatics', 'http://t.co/meFE0dMSPe',\n",
    "    \n",
    "    '@RMayNurseDir', '@FNightingaleF', 'Scholars', 'talking', 'passionately', 'about', 'what', 'they', 'believe', 'in.',\n",
    "    '#informatics', '&amp;', '#skincare', 'https://t.co/m8qiUSxk0h'\n",
    "]\n",
    "\n",
    "assert_equal(flattened_words, flattened_words_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use list comprehensions to find long words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_long_words(words):\n",
    "    '''\n",
    "    Takes a list of strings. Finds every word with 10 or more characters.\n",
    "    Returns a list of tuples of the form\n",
    "    (a word with 10 or more characters, the length of that word)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    words: a list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of tuples (str, int).\n",
    "    '''\n",
    "\n",
    "    return [(word,len(word)) for word in words if (len(word)>=10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#Informatics', 12), ('Specialist', 10), ('http://t.co/3SlUy11dro', 22), ('#Informatics', 12), ('Pharmacist', 10), ('http://t.co/4Qw8i6YaJI', 22), ('Biomedical', 10), ('Informatics,', 12), ('University', 10), ('https://t.co/65G8dJmhdR', 23), ('#informatics', 12), ('#healthcare', 11), ('#Informatics', 12), ('http://t.co/meFE0dMSPe', 22), ('@RMayNurseDir', 13), ('@FNightingaleF', 14), ('passionately', 12), ('#informatics', 12), ('https://t.co/m8qiUSxk0h', 23)]\n"
     ]
    }
   ],
   "source": [
    "long_words = get_long_words(flattened_words)\n",
    "print(long_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assertion test\n",
    "long_words_answer = [\n",
    "    ('#Informatics', 12),\n",
    "    ('Specialist', 10),\n",
    "    ('http://t.co/3SlUy11dro', 22),\n",
    "    ('#Informatics', 12),\n",
    "    ('Pharmacist', 10),\n",
    "    ('http://t.co/4Qw8i6YaJI', 22),\n",
    "    ('Biomedical', 10),\n",
    "    ('Informatics,', 12),\n",
    "    ('University', 10),\n",
    "    ('https://t.co/65G8dJmhdR', 23),\n",
    "    ('#informatics', 12),\n",
    "    ('#healthcare', 11),\n",
    "    ('#Informatics', 12),\n",
    "    ('http://t.co/meFE0dMSPe', 22),\n",
    "    ('@RMayNurseDir', 13),\n",
    "    ('@FNightingaleF', 14),\n",
    "    ('passionately', 12),\n",
    "    ('#informatics', 12),\n",
    "    ('https://t.co/m8qiUSxk0h', 23)\n",
    "]\n",
    "\n",
    "assert_equal(len(long_words), len(long_words_answer))\n",
    "assert_equal(set(long_words), set(long_words_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#Informatics',\n",
       " 'Specialist',\n",
       " 'http://t.co/3SlUy11dro',\n",
       " '#Informatics',\n",
       " 'Pharmacist',\n",
       " 'http://t.co/4Qw8i6YaJI',\n",
       " 'Biomedical',\n",
       " 'Informatics,',\n",
       " 'University',\n",
       " 'https://t.co/65G8dJmhdR',\n",
       " '#informatics',\n",
       " '#healthcare',\n",
       " '#Informatics',\n",
       " 'http://t.co/meFE0dMSPe',\n",
       " '@RMayNurseDir',\n",
       " '@FNightingaleF',\n",
       " 'passionately',\n",
       " '#informatics',\n",
       " 'https://t.co/m8qiUSxk0h']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: len(x)>=10, flattened_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Rewrite get_long_words() using map() and filter()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_long_words(words):\n",
    "    '''\n",
    "    Takes a list of strings. Finds every word with 10 or more characters.\n",
    "    Returns a list of tuples of the form\n",
    "    (a word with 10 or more characters, the length of that word)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    words: a list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of tuples (str, int).\n",
    "    '''\n",
    "    \n",
    "    return list(map(lambda x: (x, len(x)), filter(lambda x: len(x)>=10,words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('#Informatics', 12), ('Specialist', 10), ('http://t.co/3SlUy11dro', 22), ('#Informatics', 12), ('Pharmacist', 10), ('http://t.co/4Qw8i6YaJI', 22), ('Biomedical', 10), ('Informatics,', 12), ('University', 10), ('https://t.co/65G8dJmhdR', 23), ('#informatics', 12), ('#healthcare', 11), ('#Informatics', 12), ('http://t.co/meFE0dMSPe', 22), ('@RMayNurseDir', 13), ('@FNightingaleF', 14), ('passionately', 12), ('#informatics', 12), ('https://t.co/m8qiUSxk0h', 23)]\n"
     ]
    }
   ],
   "source": [
    "mapped_long_words = map_long_words(flattened_words)\n",
    "print(mapped_long_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assertion test\n",
    "assert_equal(len(mapped_long_words), len(long_words_answer))\n",
    "assert_equal(set(mapped_long_words), set(long_words_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Find hashtags using list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hashtags(words):\n",
    "    '''\n",
    "    Takes a list of strings.\n",
    "    Returns a list of strings that all start with #.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    words: a list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings.\n",
    "    '''\n",
    "    \n",
    "    return list(i for word in words for i in re.findall('\\#.*', word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#job', '#Ottawa', '#Clinical', '#Informatics', '#jobs', '#Clinical', '#Informatics', '#jobs', '#HIT', '#UChicago', '#informatics', '#healthcare', '#Books', '#EHR', '#HIE', '#HIPAA', '#Health', '#Informatics', '#informatics', '#skincare']\n"
     ]
    }
   ],
   "source": [
    "hashtags = get_hashtags(flattened_words)\n",
    "print(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assertion test\n",
    "hashtags_answer = [\n",
    "    '#job', '#Ottawa', '#Clinical', '#Informatics', '#jobs',\n",
    "    '#Clinical', '#Informatics', '#jobs', '#HIT', '#UChicago',\n",
    "    '#informatics', '#healthcare', '#Books', '#EHR', '#HIE',\n",
    "    '#HIPAA', '#Health', '#Informatics', '#informatics', '#skincare'\n",
    "]\n",
    "\n",
    "assert_equal(len(hashtags), len(hashtags_answer))\n",
    "assert_equal(set(hashtags), set(hashtags_answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Find hashtags using map() and filter()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_hashtags(words):\n",
    "    '''\n",
    "    Takes a list of strings.\n",
    "    Returns a list of strings that all start with #.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    words: a list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings.\n",
    "    '''\n",
    "    \n",
    "    return flatten(list(filter(lambda x: x!=[], map(lambda x: re.findall('\\#.*', x), words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#job', '#Ottawa', '#Clinical', '#Informatics', '#jobs', '#Clinical', '#Informatics', '#jobs', '#HIT', '#UChicago', '#informatics', '#healthcare', '#Books', '#EHR', '#HIE', '#HIPAA', '#Health', '#Informatics', '#informatics', '#skincare']\n"
     ]
    }
   ],
   "source": [
    "mapped_hashtags = map_hashtags(flattened_words)\n",
    "print(mapped_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#job'],\n",
       " ['#Ottawa'],\n",
       " ['#Clinical'],\n",
       " ['#Informatics'],\n",
       " ['#jobs'],\n",
       " ['#Clinical'],\n",
       " ['#Informatics'],\n",
       " ['#jobs'],\n",
       " ['#HIT'],\n",
       " ['#UChicago'],\n",
       " ['#informatics'],\n",
       " ['#healthcare'],\n",
       " ['#Books'],\n",
       " ['#EHR'],\n",
       " ['#HIE'],\n",
       " ['#HIPAA'],\n",
       " ['#Health'],\n",
       " ['#Informatics'],\n",
       " ['#informatics'],\n",
       " ['#skincare']]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(filter(lambda x: x!=[], map(lambda x: re.findall('\\#.*', x), flattened_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assertion test\n",
    "assert_equal(len(mapped_hashtags), len(hashtags_answer))\n",
    "assert_equal(set(mapped_hashtags), set(hashtags_answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
